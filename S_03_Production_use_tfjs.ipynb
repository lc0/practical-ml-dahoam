{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S-03-Production-use-tfjs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lc0/practical-ml-dahoam/blob/safari/S_03_Production_use_tfjs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k_F7bWIAY7Y",
        "colab_type": "text"
      },
      "source": [
        "# Production use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jakFkVSPR5hC",
        "colab_type": "text"
      },
      "source": [
        "## Optional: check required files\n",
        "\n",
        "Or upload your own model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wdo_CSA_zaX",
        "colab_type": "code",
        "outputId": "95907e69-204f-4a52-fbd9-6907a9b87353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIyNUzZpSAHp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60cfde4e-66ba-450e-922a-30dc8d54ce93"
      },
      "source": [
        "!ls -laF /gdrive/'My Drive'/talks/2019-practical-ml/models"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 93658\n",
            "-rw------- 1 root root    15208 May 27 22:04 model_hub.h5\n",
            "-rw------- 1 root root 95890392 May 27 15:03 model_transfered_mobilenet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCghI0jjSln4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -R /gdrive/'My Drive'/talks/2019-practical-ml/models ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW_09FIbSqny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3521780d-7027-4da2-e88b-d74da77b07ad"
      },
      "source": [
        "!ls -laF models/"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 93668\n",
            "drwx------ 2 root root     4096 Oct 23 11:05 ./\n",
            "drwxr-xr-x 1 root root     4096 Oct 23 11:05 ../\n",
            "-rw------- 1 root root    15208 Oct 23 11:05 model_hub.h5\n",
            "-rw------- 1 root root 95890392 Oct 23 11:05 model_transfered_mobilenet.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN0PkZmSR4Dv",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enk_zJjC_2Sj",
        "colab_type": "code",
        "outputId": "77807c74-b17d-4378-bbcc-e0ac41212642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/33/cc0c2caf6e1dc07858b42e268a3f18c525263aad2be8dba6a8ee02b4e8bb/tensorflowjs-1.2.10.1-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 7.8MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.14.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.2.2)\n",
            "Collecting six==1.11.0 (from tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting tensorflow-hub==0.5.0 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/f18c352d84382d9c795a0f37eaf16d42ace7d161fbb0ad20bdcd5e550015/tensorflow_hub-0.5.0-py2.py3-none-any.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 27.8MB/s \n",
            "\u001b[?25hCollecting PyInquirer==1.0.3 (from tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (0.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 30.0MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0->tensorflowjs) (0.1.7)\n",
            "Collecting prompt_toolkit==1.0.14 (from PyInquirer==1.0.3->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 49.3MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0 (from PyInquirer==1.0.3->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/73/1dfa428150e3ccb0fa3e68db406e5be48698f2a979ccbcec795f28f44048/Pygments-2.4.2-py2.py3-none-any.whl (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.4MB/s \n",
            "\u001b[?25hCollecting regex>=2016.11.21 (from PyInquirer==1.0.3->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs) (41.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.1.7)\n",
            "Building wheels for collected packages: PyInquirer\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32853 sha256=bb98f768e90ce87535c1be209b68a7719c21090a346331f8803f14606018bfb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "Successfully built PyInquirer\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, six, tensorboard, tensorflow-estimator, tensorflow, tensorflow-hub, prompt-toolkit, Pygments, regex, PyInquirer, tensorflowjs\n",
            "  Found existing installation: numpy 1.16.5\n",
            "    Uninstalling numpy-1.16.5:\n",
            "      Successfully uninstalled numpy-1.16.5\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "  Found existing installation: tensorflow-hub 0.6.0\n",
            "    Uninstalling tensorflow-hub-0.6.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.6.0\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.4.2 numpy-1.16.4 prompt-toolkit-1.0.14 regex-2019.8.19 six-1.11.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 tensorflow-hub-0.5.0 tensorflowjs-1.2.10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "prompt_toolkit",
                  "pygments",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBxrDH_xBynw",
        "colab_type": "text"
      },
      "source": [
        "Convert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0od_3JqVEsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MODEL = 'model_hub.h5'\n",
        "MODEL = 'model_transfered_mobilenet.h5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDn1srCAArcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --input_format keras \\\n",
        "                        models/$MODEL \\\n",
        "                        prod/tfjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQlfVXjBBPF0",
        "colab_type": "code",
        "outputId": "cc22dc38-7ed2-4af0-8c85-efa41ae6fb94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!ls -laF prod/tfjs"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 31216\n",
            "drwxr-xr-x 2 root root    4096 Oct 23 11:06 ./\n",
            "drwxr-xr-x 3 root root    4096 Oct 23 11:06 ../\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard1of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard2of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard3of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard4of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard5of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard6of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard7of8.bin\n",
            "-rw-r--r-- 1 root root 2586132 Oct 23 11:06 group1-shard8of8.bin\n",
            "-rw-r--r-- 1 root root    4933 Oct 23 11:06 model.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RGCx9SYDwgy",
        "colab_type": "text"
      },
      "source": [
        "## App base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYzTzkisT05_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "3bc66b76-49c5-4db3-b7b2-b7d05ffee56c"
      },
      "source": [
        "!wget https://github.com/lc0/practical-ml-dahoam/blob/master/prod/tfjs/shoe.png?raw=true -O prod/tfjs/shoe.png\n",
        "!ls -laF prod/tfjs"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 11:20:44--  https://github.com/lc0/practical-ml-dahoam/blob/master/prod/tfjs/shoe.png?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/lc0/practical-ml-dahoam/raw/master/prod/tfjs/shoe.png [following]\n",
            "--2019-10-23 11:20:44--  https://github.com/lc0/practical-ml-dahoam/raw/master/prod/tfjs/shoe.png\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/lc0/practical-ml-dahoam/master/prod/tfjs/shoe.png [following]\n",
            "--2019-10-23 11:20:45--  https://raw.githubusercontent.com/lc0/practical-ml-dahoam/master/prod/tfjs/shoe.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56194 (55K) [image/png]\n",
            "Saving to: ‘prod/tfjs/shoe.png’\n",
            "\n",
            "prod/tfjs/shoe.png  100%[===================>]  54.88K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-10-23 11:20:45 (2.18 MB/s) - ‘prod/tfjs/shoe.png’ saved [56194/56194]\n",
            "\n",
            "total 31284\n",
            "drwxr-xr-x 2 root root    4096 Oct 23 11:15 ./\n",
            "drwxr-xr-x 3 root root    4096 Oct 23 11:06 ../\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard1of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard2of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard3of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard4of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard5of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard6of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 Oct 23 11:06 group1-shard7of8.bin\n",
            "-rw-r--r-- 1 root root 2586132 Oct 23 11:06 group1-shard8of8.bin\n",
            "-rw-r--r-- 1 root root     973 Oct 23 11:15 index.html\n",
            "-rw-r--r-- 1 root root    3825 Oct 23 11:13 main.js\n",
            "-rw-r--r-- 1 root root    4933 Oct 23 11:06 model.json\n",
            "-rw-r--r-- 1 root root    1073 Oct 23 11:13 shoe.jpg\n",
            "-rw-r--r-- 1 root root   56194 Oct 23 11:20 shoe.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIQLRdFDzql",
        "colab_type": "code",
        "outputId": "bd230966-d7b6-44be-9643-d49176ffca64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile prod/tfjs/index.html\n",
        "\n",
        "\n",
        "<html>\n",
        "<head>\n",
        "    <!-- Load the latest version of TensorFlow.js -->\n",
        "    <script src=\"https://unpkg.com/@tensorflow/tfjs\"></script>\n",
        "    <script src=\"https://unpkg.com/@tensorflow-models/mobilenet\"></script>\n",
        "    <script src=\"https://unpkg.com/@tensorflow-models/knn-classifier\"></script>\n",
        "\n",
        "</head>\n",
        "<body>\n",
        "    <style>\n",
        "        .pred-container {\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        .pred-container > div {\n",
        "            display: inline-block;\n",
        "            margin-right: 20px;\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        .row {\n",
        "            display: table-row;\n",
        "        }\n",
        "        .cell {\n",
        "            display: table-cell;\n",
        "            padding-right: 20px;\n",
        "        }\n",
        "        #file-container {\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        </style>\n",
        "    <img id=\"img\" crossOrigin src=\"shoe.png\" width=192 height=192/>\n",
        "    <div id=\"predictions\"></div>\n",
        "\n",
        "\n",
        "    <!-- Load index.js after the content of the page -->\n",
        "    <script src=\"main.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting prod/tfjs/index.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOh2NryEQ4x",
        "colab_type": "code",
        "outputId": "0e3e01e5-44a3-4b2d-96d0-cc7fee14c484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile prod/tfjs/main.js\n",
        "\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 192\n",
        "CLASSES = ['converse chuck 70', 'Exaggerated Soles', 'nike air max 90 essentials', 'nike react', 'Tie Dye sneakers']\n",
        "\n",
        "const predictionsElement = document.getElementById('predictions');\n",
        "\n",
        "async function app() {\n",
        "  console.log('Loading model..');\n",
        "\n",
        "  // Load the model.\n",
        "  const model = await tf.loadLayersModel('/model.json');\n",
        "  console.log('Sucessfully loaded model');\n",
        "\n",
        "  // Make a prediction through the model on our image.\n",
        "  const imgEl = document.getElementById('img');\n",
        "\n",
        "\n",
        "  const result = await classify(model, imgEl);\n",
        "  console.log(result);\n",
        "}\n",
        "\n",
        "\n",
        "async function classify(model, imgElement) {\n",
        "  console.log('Predicting...');\n",
        "\n",
        "  // The first start time includes the time it takes to extract the image\n",
        "  // from the HTML and preprocess it, in additon to the predict() call.\n",
        "  const startTime1 = performance.now();\n",
        "  // The second start time excludes the extraction and preprocessing and\n",
        "  // includes only the predict() call.\n",
        "  let startTime2;\n",
        "  const logits = tf.tidy(() => {\n",
        "    // tf.browser.fromPixels() returns a Tensor from an image element.\n",
        "    const img = tf.browser.fromPixels(imgElement, 3).toFloat();\n",
        "\n",
        "    // Normalize the image from [0, 255] to [-1, 1].\n",
        "    // const offset = tf.scalar(127.5);\n",
        "    // const normalized = img.sub(offset).div(offset);\n",
        "    normalized = img\n",
        "\n",
        "    // Reshape to a single-element batch so we can pass it to predict.\n",
        "    const batched = normalized.reshape([1, IMAGE_SIZE, IMAGE_SIZE, 3]);\n",
        "\n",
        "\n",
        "\n",
        "    startTime2 = performance.now();\n",
        "    // Make a prediction through mobilenet.\n",
        "    return model.predict(batched);\n",
        "  });\n",
        "\n",
        "  console.log(\"Logits from model: \", logits)\n",
        "\n",
        "  // Convert logits to probabilities and class names.\n",
        "  classes = await getTopKClasses(logits, 2);\n",
        "  console.log(\"Predicred classes: \", classes)\n",
        "\n",
        "  const totalTime1 = performance.now() - startTime1;\n",
        "  const totalTime2 = performance.now() - startTime2;\n",
        "  console.log(`Done in ${Math.floor(totalTime1)} ms ` +\n",
        "      `(not including preprocessing: ${Math.floor(totalTime2)} ms)`);\n",
        "\n",
        "  showResults(imgElement, classes);\n",
        "}\n",
        "\n",
        "async function getTopKClasses(logits, topK) {\n",
        "  const values = await logits.data();\n",
        "\n",
        "  const valuesAndIndices = [];\n",
        "  for (let i = 0; i < values.length; i++) {\n",
        "    valuesAndIndices.push({value: values[i], index: i});\n",
        "  }\n",
        "  valuesAndIndices.sort((a, b) => {\n",
        "    return b.value - a.value;\n",
        "  });\n",
        "  const topkValues = new Float32Array(topK);\n",
        "  const topkIndices = new Int32Array(topK);\n",
        "  for (let i = 0; i < topK; i++) {\n",
        "    topkValues[i] = valuesAndIndices[i].value;\n",
        "    topkIndices[i] = valuesAndIndices[i].index;\n",
        "  }\n",
        "\n",
        "  const topClassesAndProbs = [];\n",
        "  for (let i = 0; i < topkIndices.length; i++) {\n",
        "    topClassesAndProbs.push({\n",
        "      className: CLASSES[topkIndices[i]],\n",
        "      probability: topkValues[i]\n",
        "    })\n",
        "  }\n",
        "  return topClassesAndProbs;\n",
        "}\n",
        "\n",
        "function showResults(imgElement, classes) {\n",
        "  const predictionContainer = document.createElement('div');\n",
        "  predictionContainer.className = 'pred-container';\n",
        "\n",
        "  const imgContainer = document.createElement('div');\n",
        "  imgContainer.appendChild(imgElement);\n",
        "  predictionContainer.appendChild(imgContainer);\n",
        "\n",
        "  const probsContainer = document.createElement('div');\n",
        "  for (let i = 0; i < classes.length; i++) {\n",
        "    const row = document.createElement('div');\n",
        "    row.className = 'row';\n",
        "\n",
        "    const classElement = document.createElement('div');\n",
        "    classElement.className = 'cell';\n",
        "    classElement.innerText = classes[i].className;\n",
        "    row.appendChild(classElement);\n",
        "\n",
        "    const probsElement = document.createElement('div');\n",
        "    probsElement.className = 'cell';\n",
        "    probsElement.innerText = classes[i].probability.toFixed(3);\n",
        "    row.appendChild(probsElement);\n",
        "\n",
        "    probsContainer.appendChild(row);\n",
        "  }\n",
        "  predictionContainer.appendChild(probsContainer);\n",
        "\n",
        "  predictionsElement.insertBefore(\n",
        "      predictionContainer, predictionsElement.firstChild);\n",
        "}\n",
        "\n",
        "\n",
        "app();"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting prod/tfjs/main.js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7MUHv7_wU0",
        "colab_type": "text"
      },
      "source": [
        "### Serve our app directly from Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzYJUv6FfrO",
        "colab_type": "text"
      },
      "source": [
        "Serve files with python server module like \n",
        "\n",
        "```bash\n",
        "python3 -m http.server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nACLIxmLST9B",
        "colab_type": "text"
      },
      "source": [
        "To see the result of work of the server we need `ngrock` for opening the port to outside"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9D2Lj1USTd9",
        "colab_type": "code",
        "outputId": "d5a1e37b-7406-4d43-9cc6-c57898d7aeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-23 11:06:51--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.236.27.247, 3.218.65.25, 3.227.43.216, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.236.27.247|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  6.49MB/s    in 2.0s    \n",
            "\n",
            "2019-10-23 11:06:54 (6.49 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XstbUYmOBLPl",
        "colab_type": "text"
      },
      "source": [
        "Now let's make `ngrok` to proxy the traffic from the localhost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxQAmqtS2-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8000 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiHmmP6KTdZR",
        "colab_type": "code",
        "outputId": "bc6a156e-af58-425e-a7e1-4972cabfa70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://ba90dce6.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrrkIGSftl5l",
        "colab_type": "code",
        "outputId": "f17b5d0a-06a7-4487-8cd7-a98f5533a414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!cd prod/tfjs/ && python3 -m http.server"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:06] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:06] \"GET /main.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:06] \"GET /shoe.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:07] \"GET /model.json HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:07] code 404, message File not found\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:07] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard1of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard2of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard4of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard5of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard6of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:08] \"GET /group1-shard3of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:11] \"GET /group1-shard7of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [23/Oct/2019 11:21:11] \"GET /group1-shard8of8.bin HTTP/1.1\" 200 -\n",
            "\n",
            "Keyboard interrupt received, exiting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbsi_2NIuBwK",
        "colab_type": "text"
      },
      "source": [
        "Now you can open the `ngrok` URL and being able to see predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoXl1eoRBPYG",
        "colab_type": "text"
      },
      "source": [
        "### Links\n",
        "\n",
        "\n",
        "*  https://www.tensorflow.org/js/tutorials/conversion/import_keras\n",
        "*  https://github.com/tensorflow/tfjs-examples/blob/master/mobilenet/index.js\n",
        "* https://js.tensorflow.org/api/0.11.2/\n",
        "\n"
      ]
    }
  ]
}