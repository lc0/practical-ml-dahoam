{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Production_use-tfjs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k_F7bWIAY7Y",
        "colab_type": "text"
      },
      "source": [
        "# Production use\n",
        "## TensorFlow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wdo_CSA_zaX",
        "colab_type": "code",
        "outputId": "fc91081f-21b3-4e8d-ce92-60b2e04c33d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!ls -laF"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 40\n",
            "drwxr-xr-x 1 root root 4096 May 27 14:26 ./\n",
            "drwxr-xr-x 1 root root 4096 May 27 09:32 ../\n",
            "-rw-r--r-- 1 root root 2547 May 27 09:31 adc.json\n",
            "drwxr-xr-x 1 root root 4096 May 27 09:31 .config/\n",
            "drwxr-xr-x 3 root root 4096 May 27 09:32 dataset/\n",
            "drwxr-xr-x 8 root root 4096 May 27 13:28 logs/\n",
            "drwxr-xr-x 3 root root 4096 May 27 14:26 models/\n",
            "drwxr-xr-x 1 root root 4096 May 22 16:22 sample_data/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enk_zJjC_2Sj",
        "colab_type": "code",
        "outputId": "c665aa8c-c272-4b6d-f913-e1b233428fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflowjs in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: numpy==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.1)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.2.4)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Requirement already satisfied: tf-nightly-2.0-preview>=2.0.0.dev20190502 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.0.0.dev20190527)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.3.0->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.7)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->tensorflowjs) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.11.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.33.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator-2.0-preview in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.14.0.dev2019052700)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.1.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a0,>=1.14.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (1.14.0a20190526)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.3.0->tensorflowjs) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a0,>=1.14.0a0->tf-nightly-2.0-preview>=2.0.0.dev20190502->tensorflowjs) (0.15.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBxrDH_xBynw",
        "colab_type": "text"
      },
      "source": [
        "Convert model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDn1srCAArcT",
        "colab_type": "code",
        "outputId": "3d7558b6-0ca2-4d14-92cd-f794ff305ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!tensorflowjs_converter --input_format keras \\\n",
        "                        models/model_transfered_mobilenet.h5 \\\n",
        "                        prod/tfjs"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'\n",
            "ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'\n",
            "ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'\n",
            "ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQlfVXjBBPF0",
        "colab_type": "code",
        "outputId": "2e25914d-2e3b-4ab6-858f-1ced7ebdfac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip freeze | grep numpy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "msgpack-numpy==0.4.3.2\n",
            "numpy==1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXOIx5heCmqs",
        "colab_type": "code",
        "outputId": "c805cd10-865d-460b-c6d4-714d283c5b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.16.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 3.4MB/s \n",
            "\u001b[31mERROR: thinc 6.12.1 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.11.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflowjs 1.1.2 has requirement numpy==1.15.1, but you'll have numpy 1.16.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.15.1\n",
            "    Uninstalling numpy-1.15.1:\n",
            "      Successfully uninstalled numpy-1.15.1\n",
            "Successfully installed numpy-1.16.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5Q9STyhCo2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tensorflowjs_converter --input_format keras \\\n",
        "                        models/model_transfered_mobilenet.h5 \\\n",
        "                        prod/tfjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WN2i3gmC5S2",
        "colab_type": "code",
        "outputId": "bf3a4998-83f9-4cb5-856a-60856be73918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!ls -laF prod/tfjs/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 31216\n",
            "drwxr-xr-x 2 root root    4096 May 27 14:32 ./\n",
            "drwxr-xr-x 3 root root    4096 May 27 14:32 ../\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard1of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard2of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard3of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard4of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard5of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard6of8.bin\n",
            "-rw-r--r-- 1 root root 4194304 May 27 14:33 group1-shard7of8.bin\n",
            "-rw-r--r-- 1 root root 2586132 May 27 14:33 group1-shard8of8.bin\n",
            "-rw-r--r-- 1 root root    4930 May 27 14:33 model.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RGCx9SYDwgy",
        "colab_type": "text"
      },
      "source": [
        "## App base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIQLRdFDzql",
        "colab_type": "code",
        "outputId": "fa576cad-2e08-4d40-e661-a94c84198f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile prod/tfjs/index.html\n",
        "\n",
        "\n",
        "<html>\n",
        "<head>\n",
        "    <!-- Load the latest version of TensorFlow.js -->\n",
        "    <script src=\"https://unpkg.com/@tensorflow/tfjs\"></script>\n",
        "    <script src=\"https://unpkg.com/@tensorflow-models/mobilenet\"></script>\n",
        "    <script src=\"https://unpkg.com/@tensorflow-models/knn-classifier\"></script>\n",
        "\n",
        "</head>\n",
        "<body>\n",
        "    <style>\n",
        "        .pred-container {\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        .pred-container > div {\n",
        "            display: inline-block;\n",
        "            margin-right: 20px;\n",
        "            vertical-align: top;\n",
        "        }\n",
        "        .row {\n",
        "            display: table-row;\n",
        "        }\n",
        "        .cell {\n",
        "            display: table-cell;\n",
        "            padding-right: 20px;\n",
        "        }\n",
        "        #file-container {\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        </style>\n",
        "    <img id=\"img\" crossOrigin src=\"shoe.png\" width=192 height=192/>\n",
        "    <div id=\"predictions\"></div>\n",
        "\n",
        "\n",
        "    <!-- Load index.js after the content of the page -->\n",
        "    <script src=\"main.js\"></script>\n",
        "</body>\n",
        "</html>"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing prod/tfjs/index.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOh2NryEQ4x",
        "colab_type": "code",
        "outputId": "f83a86e7-0635-43f1-bb86-ba6ad657fab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile prod/tfjs/main.js\n",
        "\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 192\n",
        "CLASSES = ['converse chuck 70', 'Exaggerated Soles', 'nike air max 90 essentials', 'nike react', 'Tie Dye sneakers']\n",
        "\n",
        "const predictionsElement = document.getElementById('predictions');\n",
        "\n",
        "async function app() {\n",
        "  console.log('Loading model..');\n",
        "\n",
        "  // Load the model.\n",
        "  const model = await tf.loadLayersModel('/model.json');\n",
        "  console.log('Sucessfully loaded model');\n",
        "\n",
        "  // Make a prediction through the model on our image.\n",
        "  const imgEl = document.getElementById('img');\n",
        "\n",
        "\n",
        "  const result = await classify(model, imgEl);\n",
        "  console.log(result);\n",
        "}\n",
        "\n",
        "\n",
        "async function classify(model, imgElement) {\n",
        "  console.log('Predicting...');\n",
        "\n",
        "  // The first start time includes the time it takes to extract the image\n",
        "  // from the HTML and preprocess it, in additon to the predict() call.\n",
        "  const startTime1 = performance.now();\n",
        "  // The second start time excludes the extraction and preprocessing and\n",
        "  // includes only the predict() call.\n",
        "  let startTime2;\n",
        "  const logits = tf.tidy(() => {\n",
        "    // tf.browser.fromPixels() returns a Tensor from an image element.\n",
        "    const img = tf.browser.fromPixels(imgElement, 3).toFloat();\n",
        "\n",
        "    // Normalize the image from [0, 255] to [-1, 1].\n",
        "    // const offset = tf.scalar(127.5);\n",
        "    // const normalized = img.sub(offset).div(offset);\n",
        "    normalized = img\n",
        "\n",
        "    // Reshape to a single-element batch so we can pass it to predict.\n",
        "    const batched = normalized.reshape([1, IMAGE_SIZE, IMAGE_SIZE, 3]);\n",
        "\n",
        "\n",
        "\n",
        "    startTime2 = performance.now();\n",
        "    // Make a prediction through mobilenet.\n",
        "    return model.predict(batched);\n",
        "  });\n",
        "\n",
        "  console.log(\"Logits from model: \", logits)\n",
        "\n",
        "  // Convert logits to probabilities and class names.\n",
        "  classes = await getTopKClasses(logits, 2);\n",
        "  console.log(\"Predicred classes: \", classes)\n",
        "\n",
        "  const totalTime1 = performance.now() - startTime1;\n",
        "  const totalTime2 = performance.now() - startTime2;\n",
        "  console.log(`Done in ${Math.floor(totalTime1)} ms ` +\n",
        "      `(not including preprocessing: ${Math.floor(totalTime2)} ms)`);\n",
        "\n",
        "  showResults(imgElement, classes);\n",
        "}\n",
        "\n",
        "async function getTopKClasses(logits, topK) {\n",
        "  const values = await logits.data();\n",
        "\n",
        "  const valuesAndIndices = [];\n",
        "  for (let i = 0; i < values.length; i++) {\n",
        "    valuesAndIndices.push({value: values[i], index: i});\n",
        "  }\n",
        "  valuesAndIndices.sort((a, b) => {\n",
        "    return b.value - a.value;\n",
        "  });\n",
        "  const topkValues = new Float32Array(topK);\n",
        "  const topkIndices = new Int32Array(topK);\n",
        "  for (let i = 0; i < topK; i++) {\n",
        "    topkValues[i] = valuesAndIndices[i].value;\n",
        "    topkIndices[i] = valuesAndIndices[i].index;\n",
        "  }\n",
        "\n",
        "  const topClassesAndProbs = [];\n",
        "  for (let i = 0; i < topkIndices.length; i++) {\n",
        "    topClassesAndProbs.push({\n",
        "      className: CLASSES[topkIndices[i]],\n",
        "      probability: topkValues[i]\n",
        "    })\n",
        "  }\n",
        "  return topClassesAndProbs;\n",
        "}\n",
        "\n",
        "function showResults(imgElement, classes) {\n",
        "  const predictionContainer = document.createElement('div');\n",
        "  predictionContainer.className = 'pred-container';\n",
        "\n",
        "  const imgContainer = document.createElement('div');\n",
        "  imgContainer.appendChild(imgElement);\n",
        "  predictionContainer.appendChild(imgContainer);\n",
        "\n",
        "  const probsContainer = document.createElement('div');\n",
        "  for (let i = 0; i < classes.length; i++) {\n",
        "    const row = document.createElement('div');\n",
        "    row.className = 'row';\n",
        "\n",
        "    const classElement = document.createElement('div');\n",
        "    classElement.className = 'cell';\n",
        "    classElement.innerText = classes[i].className;\n",
        "    row.appendChild(classElement);\n",
        "\n",
        "    const probsElement = document.createElement('div');\n",
        "    probsElement.className = 'cell';\n",
        "    probsElement.innerText = classes[i].probability.toFixed(3);\n",
        "    row.appendChild(probsElement);\n",
        "\n",
        "    probsContainer.appendChild(row);\n",
        "  }\n",
        "  predictionContainer.appendChild(probsContainer);\n",
        "\n",
        "  predictionsElement.insertBefore(\n",
        "      predictionContainer, predictionsElement.firstChild);\n",
        "}\n",
        "\n",
        "\n",
        "app();"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing prod/tfjs/main.js\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE7MUHv7_wU0",
        "colab_type": "text"
      },
      "source": [
        "### Serve our app directly from Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZzYJUv6FfrO",
        "colab_type": "text"
      },
      "source": [
        "Serve files with python server module like \n",
        "\n",
        "```bash\n",
        "python3 -m http.server\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nACLIxmLST9B",
        "colab_type": "text"
      },
      "source": [
        "To see the result of work of the server we need `ngrock` for opening the port to outside"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9D2Lj1USTd9",
        "colab_type": "code",
        "outputId": "b669e071-e3be-44be-cf78-a0a5367c3517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-27 14:33:31--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.174.228.92, 34.195.49.195, 52.203.102.189, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.174.228.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  15.88M  42.3MB/s    in 0.4s    \n",
            "\n",
            "2019-05-27 14:33:31 (42.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XstbUYmOBLPl",
        "colab_type": "text"
      },
      "source": [
        "Now let's make `ngrok` to proxy the traffic from the localhost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxQAmqtS2-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 8000 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiHmmP6KTdZR",
        "colab_type": "code",
        "outputId": "f9fd66b0-1f40-44d1-a9a7-1207d34fd534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://13f9b62d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrrkIGSftl5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "0f7b553a-11f4-46d4-fa2f-280de89e5ef8"
      },
      "source": [
        "!cd prod/tfjs/ && python3 -m http.server"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...\n",
            "127.0.0.1 - - [27/May/2019 14:37:36] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:36] \"GET /shoe.png HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:36] \"GET /main.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:36] \"GET /model.json HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:36] \"GET /group1-shard1of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:37] \"GET /group1-shard4of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:37] \"GET /group1-shard3of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:37] \"GET /group1-shard2of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:37] \"GET /group1-shard5of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:37] \"GET /group1-shard6of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:38] \"GET /group1-shard7of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:39] \"GET /group1-shard8of8.bin HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [27/May/2019 14:37:39] code 404, message File not found\n",
            "127.0.0.1 - - [27/May/2019 14:37:39] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
            "\n",
            "Keyboard interrupt received, exiting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbsi_2NIuBwK",
        "colab_type": "text"
      },
      "source": [
        "Now you can open the `ngrok` URL and being able to see predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoXl1eoRBPYG",
        "colab_type": "text"
      },
      "source": [
        "### Links\n",
        "\n",
        "\n",
        "*  https://www.tensorflow.org/js/tutorials/conversion/import_keras\n",
        "*  https://github.com/tensorflow/tfjs-examples/blob/master/mobilenet/index.js\n",
        "* https://js.tensorflow.org/api/0.11.2/\n",
        "\n"
      ]
    }
  ]
}